{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "-hNWQi6jS4ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Lavi Nigam](https://github.com/lavinigam-gcp) |"
      ],
      "metadata": {
        "id": "coW3oVMyS5DQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebooks:\n",
        "**goo.gle/io24-gemini-api**\n",
        "\n",
        "Google AI Cookbook:\n",
        "**goo.gle/google-ai-cookbook**\n",
        "\n",
        "Vertex AI Cookbook:\n",
        "**goo.gle/vertex-ai-cookbook**"
      ],
      "metadata": {
        "id": "2CCdHv8jWIUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 - Google Cloud Vertex AI Gemini API"
      ],
      "metadata": {
        "id": "6RMTXdSRChy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[What Changed: ]\n",
        "- SDK installation\n",
        "\n",
        "Before:\n",
        "\n",
        "- ! pip install --upgrade google-generativeai\n",
        "\n",
        "After:\n",
        "\n",
        "- ! pip install --upgrade google-cloud-aiplatform"
      ],
      "metadata": {
        "id": "y7nHwXiDU-9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Library installation # needs restarts\n",
        "\n",
        "# ! pip install --upgrade google-generativeai\n",
        "! pip install --upgrade google-cloud-aiplatform\n",
        "! pip install PyPDF2\n",
        "# ! apt-get install poppler-utils\n",
        "# ! pip install pdf2image"
      ],
      "metadata": {
        "id": "vOZVZgNJDCfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[What Changed: ]\n",
        "- Authentication  \n",
        "\n",
        "Before:\n",
        "\n",
        "- genai.configure(api_key=\"API Key\")\n",
        "\n",
        "After:\n",
        "\n",
        " - Authenticate Colab user to Google Cloud\n",
        " - Vertex AI init with Project ID and Region\n",
        "\n",
        "  [Not required in Colab Enterprise]"
      ],
      "metadata": {
        "id": "x1oda7ozVODI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNDLW6CNA7dY"
      },
      "outputs": [],
      "source": [
        "# Authentication\n",
        "\n",
        "# genai.configure(api_key=\"\")\n",
        "\n",
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Define project information\n",
        "    PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "    LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "    # Initialize Vertex AI\n",
        "    import vertexai\n",
        "\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading data from Google Drive\n",
        "!gdown --folder https://drive.google.com/drive/folders/1RfMScB0Y1LUQdW5tvjyYA4_D21H5HMaT?usp=sharing -O /content/data/"
      ],
      "metadata": {
        "id": "bhSUD7Humsoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[What Changed: ]\n",
        "\n",
        "-\n",
        "\n",
        "\n",
        "Before:\n",
        "\n",
        "-\n",
        "\n",
        "After:\n",
        "\n",
        "-\n"
      ],
      "metadata": {
        "id": "308fQIDEVkqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[What Changed: ]\n",
        "\n",
        "- Import statement\n",
        "\n",
        "\n",
        "Before:\n",
        "\n",
        "- import google.generativeai as genai\n",
        "\n",
        "After:\n",
        "\n",
        "- import vertexai.generative_models as genai\n"
      ],
      "metadata": {
        "id": "pvv51eaKVn5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Library\n",
        "from IPython.display import display, Markdown, Latex\n",
        "# import google.generativeai as genai\n",
        "import vertexai.generative_models as genai\n",
        "import PyPDF2\n",
        "from rich import print as rich_print\n",
        "from rich.markdown import Markdown as rich_Markdown"
      ],
      "metadata": {
        "id": "HrPf6V_1Sown"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[No Change ]\n",
        "\n",
        "- Model Config and Safety Setting\n",
        "\n",
        "\n",
        "Before:\n",
        "\n",
        "\n",
        "\n",
        "After:\n"
      ],
      "metadata": {
        "id": "N3nFQg-DWACB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold,\n",
        ")\n",
        "\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=1,\n",
        "    max_output_tokens=8192,\n",
        ")\n",
        "\n",
        "\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-preview-0409\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "model_flash = genai.GenerativeModel(model_name=\"gemini-1.5-flash-preview-0514\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "KhTx4pNbLre7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDF\n",
        "\n",
        "[No Change]"
      ],
      "metadata": {
        "id": "YD5CkSMcbfAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helper Functions\n",
        "## Helper Function\n",
        "\n",
        "def pdf_to_dict_str(file_path):\n",
        "    \"\"\"Reads a PDF file and returns a dictionary with page numbers as keys and page text as values.\"\"\"\n",
        "\n",
        "    with open(file_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        num_pages = len(pdf_reader.pages)\n",
        "\n",
        "        page_dict = {}\n",
        "        for page_num in range(num_pages):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            page_text = page.extract_text()\n",
        "            page_dict[page_num + 1] = page_text  # Page numbers start from 1\n",
        "\n",
        "        return str(page_dict)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pwql88iWbcF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "prompt_parts = [\n",
        "  pdf_to_dict_str(\"/content/data/Idea/stage_1_prototype_Google Cloud TPU blog.pdf\"),\n",
        "  \"What are key achievement for Google Cloud from the following blog. Mention in bullet.\",\n",
        "]\n",
        "response = model.generate_content(prompt_parts)\n",
        "rich_Markdown(response.text)"
      ],
      "metadata": {
        "id": "ZzDM8-fhDa5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "response = model_flash.generate_content(prompt_parts)\n",
        "rich_Markdown(response.text)"
      ],
      "metadata": {
        "id": "WaDypW2RUWpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "prompt_parts = [\n",
        "  pdf_to_dict_str('/content/data/Idea/goog-10-q-q2-2023-4-1-15.pdf'),\n",
        "  \"\"\"Answer based on the document provided:\n",
        "- How has Google Cloud performed in last quarters?\n",
        "- What factors have influenced its numebrs and is it positive or negative?\n",
        "- What is the leadership view on Google Cloud business?\n",
        "- What are some changes and decisions they have made along the way to achieve their goals?\n",
        "- How are they doing with respect to other cloud companies?\n",
        "  \"\"\",\n",
        "]\n",
        "response = model.generate_content(prompt_parts)\n",
        "rich_Markdown(response.text)"
      ],
      "metadata": {
        "id": "6wFDusjknFLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "response = model_flash.generate_content(prompt_parts)\n",
        "rich_Markdown(response.text)"
      ],
      "metadata": {
        "id": "dCoYqo3ZUhke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Audio File"
      ],
      "metadata": {
        "id": "00EsLYuNbGPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[What Changed: ]\n",
        "\n",
        "- File Upload method\n",
        "\n",
        "\n",
        "Before:\n",
        "\n",
        "- genai.upload_file\n",
        "\n",
        "After:\n",
        "\n",
        "- Part.from_uri [reading from GCS]\n"
      ],
      "metadata": {
        "id": "eGomNFGQXXvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import Part"
      ],
      "metadata": {
        "id": "D1HsR1xYXuX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# earning_calls = genai.upload_file(path=\"/content/stage_1_prototype_Alphabet 2023 Q4 Earnings Call.mp3\",\n",
        "#                             display_name=\"earning_calls\")\n",
        "\n",
        "earning_calls = Part.from_uri(uri = \"gs://gemini-lavi-asset/production/earning_calls/Alphabet 2023 Q4 Earnings Call.mp3\",\n",
        "    mime_type=\"audio/mpeg\")"
      ],
      "metadata": {
        "id": "3PjkJqwwbIJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "prompt_parts = [\n",
        "  earning_calls,\n",
        "  \"How has performance max worked out for Google Ads?\",\n",
        "]\n",
        "response = model.generate_content(prompt_parts)\n",
        "rich_Markdown(response.text)"
      ],
      "metadata": {
        "id": "Z9SIRpVhbiv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "response = model_flash.generate_content(prompt_parts)\n",
        "rich_Markdown(response.text)"
      ],
      "metadata": {
        "id": "9inzbauaVLv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Images"
      ],
      "metadata": {
        "id": "sHytDs7cwmzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[What Changed: ]\n",
        "\n",
        "- File Upload method\n",
        "- PDF to Image method\n",
        "\n",
        "\n",
        "Before:\n",
        "\n",
        "- genai.upload_file\n",
        "- pdf_to_images\n",
        "\n",
        "After:\n",
        "\n",
        "- Part.from_uri [it can read pdf as image directly]\n",
        "- No need of custom function\n"
      ],
      "metadata": {
        "id": "DKEnKukSlwY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blog_pdf = Part.from_uri(uri = \"gs://gemini-lavi-asset/idea_doc/stage_1_prototype_Google Cloud TPU blog.pdf\",\n",
        "    mime_type=\"application/pdf\")"
      ],
      "metadata": {
        "id": "QR30bcWeoYnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "prompt_parts = [\n",
        "  blog_pdf,\n",
        "  \"what is the emfu for bf16 and 128b parameter model with 1 tpu v5e pod? Cite the table and page number and explain the significance of the results\",\n",
        "]\n",
        "response = model.generate_content(prompt_parts)\n",
        "rich_Markdown(response.text)"
      ],
      "metadata": {
        "id": "7dRJ6bRfpItY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "response = model_flash.generate_content(prompt_parts)\n",
        "rich_Markdown(response.text)"
      ],
      "metadata": {
        "id": "P5zaRMI3VfRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Video"
      ],
      "metadata": {
        "id": "q6fVmmQ2zefi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[What Changed: ]\n",
        "\n",
        "- File Upload method\n",
        "- Splitting video into frame\n",
        "\n",
        "Before:\n",
        "\n",
        "- genai.upload_file\n",
        "- process_video\n",
        "\n",
        "After:\n",
        "\n",
        "- Part.from_uri [reading from GCS]\n",
        "- No need to convert the video->frames\n"
      ],
      "metadata": {
        "id": "5XHD0XZzmC1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helper Functions\n",
        "## Helper Function\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def process_video(video_file_path, full_video=False):\n",
        "    \"\"\"\n",
        "    Extracts frames from a video, optionally uploads them, and returns a list of File objects.\n",
        "\n",
        "    Args:\n",
        "        video_file_path (str): Path to the video file.\n",
        "        full_video (bool, optional): If True, uploads all frames. Otherwise, uploads a 10-second slice. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of File objects, each containing file path, response (if uploaded), and timestamp.\n",
        "    \"\"\"\n",
        "\n",
        "    FRAME_EXTRACTION_DIRECTORY = \"/content/frames\"\n",
        "    FRAME_PREFIX = \"_frame\"\n",
        "\n",
        "    def create_frame_output_dir(output_dir):\n",
        "        \"\"\"Creates or cleans up the frame output directory.\"\"\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "        else:\n",
        "            shutil.rmtree(output_dir)\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "    def get_timestamp(filename):\n",
        "        \"\"\"Extracts the timestamp from a frame filename.\"\"\"\n",
        "        parts = filename.split(FRAME_PREFIX)\n",
        "        if len(parts) != 2:\n",
        "            return None  # Incorrect format\n",
        "        return parts[1].split('.')[0]\n",
        "\n",
        "    class File:\n",
        "        \"\"\"Represents a file with path, display name, timestamp, and optional response.\"\"\"\n",
        "        def __init__(self, file_path, display_name=None):\n",
        "            self.file_path = file_path\n",
        "            self.display_name = display_name or os.path.basename(file_path)\n",
        "            self.timestamp = get_timestamp(file_path)\n",
        "\n",
        "        def set_file_response(self, response):\n",
        "            self.response = response\n",
        "\n",
        "    # Extract frames\n",
        "    create_frame_output_dir(FRAME_EXTRACTION_DIRECTORY)\n",
        "    vidcap = cv2.VideoCapture(video_file_path)\n",
        "    if not vidcap.isOpened():\n",
        "        raise ValueError(\"Could not open video file.\")\n",
        "\n",
        "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_duration = 1 / fps\n",
        "    output_file_prefix = os.path.basename(video_file_path).replace('.', '_')\n",
        "    frame_count = 0\n",
        "    count = 0\n",
        "\n",
        "    while vidcap.isOpened():\n",
        "        success, frame = vidcap.read()\n",
        "        if not success:\n",
        "            break  # End of video\n",
        "\n",
        "        if int(count / fps) == frame_count:\n",
        "            min = frame_count // 60\n",
        "            sec = frame_count % 60\n",
        "            time_string = f\"{min:02d}:{sec:02d}\"\n",
        "            image_name = f\"{output_file_prefix}{FRAME_PREFIX}{time_string}.jpg\"\n",
        "            output_filename = os.path.join(FRAME_EXTRACTION_DIRECTORY, image_name)\n",
        "            cv2.imwrite(output_filename, frame)\n",
        "            frame_count += 1\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    vidcap.release()\n",
        "    print(f\"Extracted: {frame_count} frames\")\n",
        "\n",
        "    # Process and optionally upload frames\n",
        "    files = [File(os.path.join(FRAME_EXTRACTION_DIRECTORY, file)) for file in sorted(os.listdir(FRAME_EXTRACTION_DIRECTORY))]\n",
        "    files_to_upload = files if full_video else files[40:50]  # Adjust slice as needed\n",
        "\n",
        "    uploaded_files = []\n",
        "    print(f'Uploading {len(files_to_upload)} files...')\n",
        "    for file in files_to_upload:\n",
        "        print(f'Uploading: {file.file_path}...')\n",
        "        try:\n",
        "            response = genai.upload_file(path=file.file_path)  # Assuming 'genai' is available\n",
        "            file.set_file_response(response)\n",
        "            uploaded_files.append(file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error uploading {file.file_path}: {e}\")\n",
        "\n",
        "    print(f\"Uploaded: {len(uploaded_files)} files\")\n",
        "    return uploaded_files\n",
        "\n",
        "# Make GenerateContent request with the structure described above.\n",
        "def make_request(prompt, files):\n",
        "  request = [prompt]\n",
        "  for file in files:\n",
        "    request.append(file.timestamp)\n",
        "    request.append(file.response)\n",
        "  return request"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GfPC35Kmze0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Upload a video ~ 1min\n",
        "# video_file_name = \"/content/What's next for AI and Google Search _ Google I_O 2023.mp4\"\n",
        "# processed_files_search = process_video(video_file_name, full_video=True)"
      ],
      "metadata": {
        "id": "l-rus7l4-VST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = Part.from_uri(uri = \"gs://gemini-lavi-asset/idea_doc/What's next for AI and Google Search _ Google I_O 2023.mp4\",\n",
        "    mime_type=\"video/mp4\")"
      ],
      "metadata": {
        "id": "MpJNIYlXpQDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "prompt_parts = [\n",
        "  video,\n",
        "  \"Describe this video and How is google using generative ai in search? Give response in bullet\",\n",
        "]\n",
        "response = model.generate_content(prompt_parts)\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "eHMOVpdGpmVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = model_flash.generate_content(prompt_parts)\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "xX8tlOdvVkwA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}